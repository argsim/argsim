- try init with scale 1.0
- try logit embed sharing

* dropout

the vae currently does not learn when dropout is applied.
figure out why and if dropout is beneficial

* hyperparameter tuning

- word dropout rate
- model size

* attentional encoder

- bidirectional rnn
- final state as query
- outputs as values

* convolutional decoder

since we don't need to use the decoder for generation,
it does not have to be generative/autoregressive.
consider a transposed convolutional network.

* performance optimization

use time major format

consider using =tf.contrib.cudnn_rnn.CudnnGRU=
but it's a bit tricky to make it automagically compatible with the cpu version
